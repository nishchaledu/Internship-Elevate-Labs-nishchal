{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd474227",
   "metadata": {},
   "source": [
    "\n",
    "# Task 1 · Data Cleaning & Preprocessing (Titanic Example)\n",
    "**Created:** 2025-08-19 07:01\n",
    "\n",
    "This notebook walks through a practical, end-to-end preprocessing pipeline:\n",
    "\n",
    "1. Import dataset and explore basic info (nulls, data types)  \n",
    "2. Handle missing values (median/mode imputation)  \n",
    "3. Convert categorical features into numerical (one‑hot encoding)  \n",
    "4. Normalize/standardize numerical features (StandardScaler)  \n",
    "5. Visualize outliers using boxplots and remove them with IQR\n",
    "\n",
    "> **Tip:** If you have a local `titanic.csv` (or `train.csv`), place it alongside this notebook and re-run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b99b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Charts: use matplotlib only (no seaborn styling)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015998ca",
   "metadata": {},
   "source": [
    "## 1) Load a Titanic dataset (robust fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_titanic():\n",
    "    \"\"\"Load Titanic data from common local filenames, else try seaborn's built-in dataset.\n",
    "    Returns a (DataFrame, source_note).\n",
    "    \"\"\"\n",
    "    possible_files = [\"titanic.csv\", \"train.csv\", \"Titanic-Dataset.csv\", \"titanic_train.csv\"]\n",
    "    for fn in possible_files:\n",
    "        if os.path.exists(fn):\n",
    "            df = pd.read_csv(fn)\n",
    "            return df, f\"Loaded local file: {fn}\"\n",
    "    # Fall back to seaborn's sample dataset if available\n",
    "    try:\n",
    "        import seaborn as sns  # only for loading the dataset (we won't use seaborn for plotting)\n",
    "        df = sns.load_dataset(\"titanic\")\n",
    "        return df, \"Loaded seaborn sample dataset: titanic\"\n",
    "    except Exception as e:\n",
    "        # As a last resort, synthesize a tiny mock dataset (structure similar to Titanic)\n",
    "        data = {\n",
    "            \"survived\": [0,1,1,0,0,1,0,1],\n",
    "            \"pclass\":   [3,1,3,2,3,1,2,2],\n",
    "            \"sex\":      [\"male\",\"female\",\"female\",\"male\",\"male\",\"female\",\"male\",\"female\"],\n",
    "            \"age\":      [22,38,26,35,np.nan,58,14,30],\n",
    "            \"sibsp\":    [1,1,0,1,0,0,1,0],\n",
    "            \"parch\":    [0,0,0,0,0,0,2,0],\n",
    "            \"fare\":     [7.25,71.2833,7.925,8.05,8.4583,512.3292,14.4542,13.0],\n",
    "            \"embarked\": [\"S\",\"C\",\"S\",\"S\",\"Q\",\"S\",np.nan,\"C\"]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        return df, \"Using a small synthetic fallback dataset.\"\n",
    "\n",
    "df_raw, source_note = load_titanic()\n",
    "print(source_note)\n",
    "display(df_raw.head())\n",
    "print(\"Shape:\", df_raw.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ac1ee",
   "metadata": {},
   "source": [
    "## 2) Basic info & missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf80cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data types\n",
    "print(\"Data types:\")\n",
    "print(df_raw.dtypes)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values (count):\")\n",
    "print(df_raw.isna().sum())\n",
    "\n",
    "# Summary stats\n",
    "display(df_raw.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1cd92b",
   "metadata": {},
   "source": [
    "## 3) Handle missing values (median for numeric, mode for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80649055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Impute numeric with median\n",
    "for col in numeric_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Impute categorical with mode\n",
    "for col in categorical_cols:\n",
    "    if df[col].isna().any():\n",
    "        mode_val = df[col].mode(dropna=True)\n",
    "        if len(mode_val) > 0:\n",
    "            df[col] = df[col].fillna(mode_val.iloc[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb9a64",
   "metadata": {},
   "source": [
    "## 4) Encode categorical features (one‑hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify categorical columns again (post-imputation)\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# One-hot encode\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"Shape before encoding:\", df.shape)\n",
    "print(\"Shape after encoding:\", df_encoded.shape)\n",
    "display(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce547d",
   "metadata": {},
   "source": [
    "## 5) Standardize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize only the original numeric columns (that still exist after encoding)\n",
    "num_cols_after = [c for c in df_encoded.columns if c in numeric_cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df_encoded.copy()\n",
    "df_scaled[num_cols_after] = scaler.fit_transform(df_scaled[num_cols_after])\n",
    "\n",
    "display(df_scaled.head())\n",
    "\n",
    "print(\"Columns standardized:\", num_cols_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52581e55",
   "metadata": {},
   "source": [
    "## 6) Visualize outliers (boxplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80025605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choose a few numeric columns commonly used in Titanic\n",
    "candidates = [c for c in [\"fare\", \"age\", \"sibsp\", \"parch\"] if c in df.columns]\n",
    "\n",
    "for col in candidates:\n",
    "    plt.figure()\n",
    "    plt.boxplot(df[col].dropna())\n",
    "    plt.title(f\"Boxplot for {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb006bf",
   "metadata": {},
   "source": [
    "## 7) Remove outliers by IQR (per selected numeric columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iqr_filter(dataframe, cols, k=1.5):\n",
    "    mask = pd.Series([True]*len(dataframe), index=dataframe.index)\n",
    "    for col in cols:\n",
    "        if col in dataframe.columns:\n",
    "            q1 = dataframe[col].quantile(0.25)\n",
    "            q3 = dataframe[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower = q1 - k*iqr\n",
    "            upper = q3 + k*iqr\n",
    "            mask &= dataframe[col].between(lower, upper, inclusive=\"both\")\n",
    "    return dataframe[mask]\n",
    "\n",
    "print(\"Rows before IQR filtering:\", len(df))\n",
    "df_no_outliers = iqr_filter(df, candidates, k=1.5)\n",
    "print(\"Rows after IQR filtering:\", len(df_no_outliers))\n",
    "\n",
    "# Re-encode & rescale after outlier removal\n",
    "df_no_outliers_encoded = pd.get_dummies(df_no_outliers, columns=[c for c in df_no_outliers.select_dtypes(exclude=[np.number]).columns], drop_first=True)\n",
    "num_cols_after_no = [c for c in df_no_outliers_encoded.columns if c in numeric_cols]\n",
    "scaler2 = StandardScaler()\n",
    "df_no_outliers_scaled = df_no_outliers_encoded.copy()\n",
    "if num_cols_after_no:\n",
    "    df_no_outliers_scaled[num_cols_after_no] = scaler2.fit_transform(df_no_outliers_scaled[num_cols_after_no])\n",
    "\n",
    "display(df_no_outliers_scaled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7884b934",
   "metadata": {},
   "source": [
    "## 8) Save processed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c988527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_paths = {}\n",
    "out_paths[\"clean_imputed_encoded_scaled.csv\"] = \"/mnt/data/clean_imputed_encoded_scaled.csv\"\n",
    "out_paths[\"clean_no_outliers_encoded_scaled.csv\"] = \"/mnt/data/clean_no_outliers_encoded_scaled.csv\"\n",
    "\n",
    "df_scaled.to_csv(out_paths[\"clean_imputed_encoded_scaled.csv\"], index=False)\n",
    "df_no_outliers_scaled.to_csv(out_paths[\"clean_no_outliers_encoded_scaled.csv\"], index=False)\n",
    "\n",
    "out_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1247f11",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Interview Quick Answers\n",
    "\n",
    "**Q1. What are the different types of missing data?**  \n",
    "- **MCAR** (Missing Completely At Random): missingness unrelated to any variable.  \n",
    "- **MAR** (Missing At Random): missingness depends on observed variables.  \n",
    "- **MNAR** (Missing Not At Random): missingness depends on the unobserved value itself.\n",
    "\n",
    "**Q2. How do you handle categorical variables?**  \n",
    "- Encoding: **one‑hot** for nominal variables, **ordinal/label** for ordered categories. Consider target/mean encoding with care to avoid leakage.\n",
    "\n",
    "**Q3. Normalization vs Standardization?**  \n",
    "- **Normalization** scales to a range (often 0–1, e.g., Min‑Max).  \n",
    "- **Standardization** centers to mean 0, std 1 (z‑score).\n",
    "\n",
    "**Q4. How do you detect outliers?**  \n",
    "- IQR (Q3−Q1), z‑scores, domain rules, model residuals. Visualize via boxplots, histograms, scatterplots.\n",
    "\n",
    "**Q5. Why is preprocessing important in ML?**  \n",
    "- Improves data quality, model convergence, and accuracy; reduces bias/leakage; makes features comparable.\n",
    "\n",
    "**Q6. One‑hot vs Label encoding?**  \n",
    "- **One‑hot:** creates binary columns per category (no order implied).  \n",
    "- **Label:** assigns integer codes (implies order; suitable for tree models or true ordinal data).\n",
    "\n",
    "**Q7. How do you handle data imbalance?**  \n",
    "- Resampling (over/under, SMOTE), class‑weighted losses, appropriate metrics (ROC‑AUC, PR‑AUC, F1).\n",
    "\n",
    "**Q8. Can preprocessing affect model accuracy?**  \n",
    "- Yes. Correct imputation, encoding, scaling, and outlier handling often yield measurable gains and more stable models.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
